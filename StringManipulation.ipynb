{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing String Manipulation (Regular Expression in Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aeo\n",
      "yad emosewA\n"
     ]
    }
   ],
   "source": [
    "my_string = \"Awesome day\"\n",
    "print(my_string[0:6:2])#print every 2 character\n",
    "print(my_string[::-1])#print reverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the film, hower, is all good\n",
      "['the film', ' hower', ' is all good']\n",
      "the film  hower  is all good\n"
     ]
    }
   ],
   "source": [
    "movie=\"the film, hower, is all good<\\i>\"\n",
    "movie_tag = movie.rstrip(\"<\\i>\")\n",
    "print(movie_tag)\n",
    "\n",
    "# Split the string using commas and print results\n",
    "movie_no_comma = movie_tag.split(\",\")\n",
    "print(movie_no_comma)\n",
    "\n",
    "# Join back together and print results\n",
    "movie_join = \" \".join(movie_no_comma)\n",
    "print(movie_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Donald Trump will participate in a town hall with NBC News on Thursday night\n",
      ", setting up a competing television event\n",
      " with Joe Biden in lieu of a presidential debate in which voters would have seen both presidential candidates engage with each other and discuss issues head-to-head.\n",
      "['President Donald Trump will participate in a town hall with NBC News on Thursday night', ', setting up a competing television event', ' with Joe Biden in lieu of a presidential debate in which voters would have seen both presidential candidates engage with each other and discuss issues head-to-head.']\n",
      "['President Donald Trump will participate in a town hall with NBC News on Thursday night']\n",
      "['', ' setting up a competing television event']\n",
      "[' with Joe Biden in lieu of a presidential debate in which voters would have seen both presidential candidates engage with each other and discuss issues head-to-head.']\n"
     ]
    }
   ],
   "source": [
    "file=\"President Donald Trump will participate in a town hall with NBC News on Thursday night\\n, setting up a competing television event\\n with Joe Biden in lieu of a presidential debate in which voters would have seen both presidential candidates engage with each other and discuss issues head-to-head.\"\n",
    "print(file)\n",
    "# Split string at line boundaries\n",
    "file_split = file.splitlines()\n",
    "\n",
    "# Print file_split\n",
    "print(file_split)\n",
    "\n",
    "# Complete for-loop to split by commas\n",
    "for substring in file_split:\n",
    "    substring_split = substring.split(sep=\",\")\n",
    "    print(substring_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies)\n",
    "for movie in movies:\n",
    "  \t# Find if actor occurrs between 37 and 41 inclusive\n",
    "    if movie.find(\"actor\", 37, 42) == -1:\n",
    "        print(\"Word not found\")\n",
    "    # Count occurrences and replace two by one\n",
    "    elif movie.count(\"actor\") == 2:  \n",
    "        print(movie.replace(\"actor actor\", \"actor\"))\n",
    "    else:\n",
    "        # Replace three occurrences by one\n",
    "        print(movie.replace(\"actor actor actor\", \"actor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie in movies:\n",
    "  try:\n",
    "    # Find the first occurrence of word\n",
    "      print(movie.index('money', 12, 51))\n",
    "  except ValueError:\n",
    "    print(\"substring not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kukhwa Is Awesome\n"
     ]
    }
   ],
   "source": [
    "x = \" \".join([\"kukhwa\", \"is\", \"awesome\"])\n",
    "\n",
    "print(x.title()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Donald Trump \n",
      " Participate \n",
      "Who? President Donald Trump what? Participate \n",
      "What? Participate  Who? President Donald Trump\n",
      "['Who? {} what? {}', 'What? {1} Who? {0}']\n"
     ]
    }
   ],
   "source": [
    "# Assign the substrings to the variables\n",
    "first_pos = file[0:22].title()# upper, lower, title\n",
    "second_pos = file[28:40].title()\n",
    "my_list=[]\n",
    "print(first_pos,\"\\n\",second_pos)\n",
    "# Define string with placeholders \n",
    "my_list.append(\"Who? {} what? {}\")\n",
    "\n",
    "# Define string with rearranged placeholders\n",
    "my_list.append(\"What? {1} Who? {0}\")\n",
    "\n",
    "# Use format to print strings\n",
    "for my_string in my_list:\n",
    "  \tprint(my_string.format(first_pos, second_pos))\n",
    "\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine learning', 'deep learning']\n"
     ]
    }
   ],
   "source": [
    "courses=['machine learning','deep learning']\n",
    "print(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are interested in machine learning, you can take the course related to deep learning\n"
     ]
    }
   ],
   "source": [
    "plan = {\n",
    "        \"field\": courses[0],\n",
    "        \"tool\": courses[1]\n",
    "        }\n",
    "\n",
    "# Complete the placeholders accessing elements of field and tool keys\n",
    "my_message = \"If you are interested in {data[field]}, you can take the course related to {data[tool]}\"\n",
    "\n",
    "# Use dictionary to replace placeholders\n",
    "print(my_message.format(data=plan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datetime \n",
    "from datetime import datetime\n",
    "\n",
    "# Assign date to get_date\n",
    "get_date = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning. Today is October 15, 2020. It's 13:44 ... time to work!\n"
     ]
    }
   ],
   "source": [
    "# Add named placeholders with format specifiers\n",
    "message = \"Good morning. Today is {today:%B %d, %Y}. It's {today:%H:%M} ... time to work!\"\n",
    "\n",
    "# Format date\n",
    "print(message.format(today=get_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fstrings\n",
    "- !s(stringversion)\n",
    "- !r(stringcontainingaprintablerepresentation,i.e.withquotes)\n",
    "- !a(someas!rbutescapethenon-ASCIIcharacters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuals create around 72.41% of the data but only 1.1% is analyzed\n",
      "INDIVIDUALS create around 72.414164% of the data but only 1.090000e+00% is analyzed\n",
      "'individuals' create around 72.41416415% of the data but only 1.09% is analyzed\n"
     ]
    }
   ],
   "source": [
    "field3=\"individuals\"\n",
    "fact3=72.41416415\n",
    "fact4=1.09\n",
    "\n",
    "print(f\"{field3.title()} create around {fact3:.2f}% of the data but only {fact4:.1f}% is analyzed\")\n",
    "print(f\"{field3.upper()} create around {fact3:f}% of the data but only {fact4:e}% is analyzed\")\n",
    "print(f\"{field3!r} create around {fact3!s}% of the data but only {fact4!a}% is analyzed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public.tableau.com/profile/kukhwa.kim#!/\n"
     ]
    }
   ],
   "source": [
    "string1=\"httpspublic.tableau.com/profile/kukhwa.kim#!/\"\n",
    "# Replace the substring https by an empty string\n",
    "print(f\"{string1.replace('https','')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are offering a 3-month beginner course on knitting just for $ 20 monthly\n"
     ]
    }
   ],
   "source": [
    "# Import template\n",
    "from string import Template\n",
    "\n",
    "tools=['knitting','20','month']\n",
    "# Select variables\n",
    "our_tool = tools[0]\n",
    "our_fee = tools[1]\n",
    "our_pay = tools[2]\n",
    "\n",
    "# Create template\n",
    "course = Template(\"We are offering a 3-month beginner course on $tool just for $$ $fee ${pay}ly\")\n",
    "\n",
    "# Substitute identifiers with three variables\n",
    "print(course.substitute(tool=our_tool, fee=our_fee, pay=our_pay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex\n",
    "- \\d: digit\n",
    "- \\w: word character\n",
    "- \\W: non-word character\n",
    "- \\s: whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@robot1!', '@robot2@', '@robot3#']\n"
     ]
    }
   ],
   "source": [
    "regex = r\"@robot\\d\\W\"\n",
    "print(re.findall(regex, \"sentiment_analysis @robot1!, @robot2@, @robot3# ,@bot4$\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https:\\\\public.tableau.com/profile/kukhwa.kim#!/']\n",
      "[]\n",
      "[]\n",
      "['@kukhwa', '@hotdog8282']\n"
     ]
    }
   ],
   "source": [
    "# Import re module\n",
    "import re\n",
    "sentiment_analysis=[\"https:\\\\public.tableau.com/profile/kukhwa.kim#!/\", \"@kukhwa @hotdog8282\"]\n",
    "for tweet in sentiment_analysis:\n",
    "    print(re.findall(r\"http\\S+\", tweet))\n",
    "    print(re.findall(r\"@\\w+\", tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for time: 1st september 2019 17:25.\n",
    "for date in sentiment_analysis:\n",
    "    print(re.findall(r\"\\d{1,2}\\w+\\s\\w+\\s\\d{4}\\s\\d{2}:\\d{1,2}\", date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize text\n",
    "You realize that hashtags start with a # symbol and contain letters and numbers but never whitespace. After that, you plan to split the text at whitespace matches to get the tokens. * zero o more times,  + once or more, ? zero or once, {n, m} minimum n, maximum m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'miss', 'you', 'so', 'much', '']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis=\"I miss you so much #missyou #forever #beaucoup\"\n",
    "regex = r\"#\\w+\"\n",
    "\n",
    "# Replace the regex by an empty string\n",
    "no_hashtag = re.sub(regex,\"\", sentiment_analysis)\n",
    "\n",
    "# Get tokens by splitting text\n",
    "print(re.split(r\"\\s+\", no_hashtag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metacharacters\n",
    "^ anchor to beginning, . any character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"^[aeiouAEIOU]{2,3}.+txt\"\n",
    "\n",
    "for text in sentiment_analysis:\n",
    "\t# Find all matches of the regex\n",
    "\tprint(re.findall(regex, text))\n",
    "    \n",
    "\t# Replace all matches with empty string\n",
    "\tprint(re.sub(regex, \"\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"[A-Za-z0-9!#%&*\\$\\.]+@\\w+\\.com\" # for $ and . use \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy vs Greedy\n",
    "- dot (.) is a special character used to match any one character\n",
    "- Standard quantiers are greedy by default: *, +, ?, {num, num}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to see that amazing movie again!\n"
     ]
    }
   ],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "string= \"I want to see that <strong>amazing movie</strong> again!\"\n",
    "\n",
    "# Write a regex to eliminate tags\n",
    "string_notags = re.sub(r\"<.+?>\", \"\", string)\n",
    "\n",
    "# Print out the result\n",
    "print(string_notags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '0', '1', '9', '1', '9', '8', '3']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis=\"I was born in Oct(10) 19th in 1983\"\n",
    "numbers_found_lazy = re.findall(r\"\\d+?\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '19', '1983']\n"
     ]
    }
   ],
   "source": [
    "numbers_found_greedy = re.findall(r\"\\d+\", sentiment_analysis)\n",
    "\n",
    "# Print out the result\n",
    "print(numbers_found_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(10)', '(South)']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis= \"I was born in Oct(10) 19th in 1983 in Seoul,(South) Korea\"\n",
    "sentences_found_lazy = re.findall(r\"\\(.*?\\)\", sentiment_analysis)\n",
    "\n",
    "# Print out the results\n",
    "print(sentences_found_lazy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists of users found in this tweet: ['email1', 'email2', 'email3']\n"
     ]
    }
   ],
   "source": [
    "sentimental_analysis=\" This is fake email address email1@gmail.com and email2@hotmail.com and lastly this is also a fake email email3@live.com\"\n",
    "\n",
    "regex_email = r\"([a-zA-Z0-9]+\\S+)@\"\n",
    "\n",
    "#for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in each tweet\n",
    "email_matched = re.findall(regex_email, sentimental_analysis)\n",
    "\n",
    "    # Complete the format method to print the results\n",
    "print(\"Lists of users found in this tweet: {}\".format(email_matched))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flight info extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline: LA Flight number: 4214\n",
      "Departure: AER Destination: CDB\n",
      "Date: 06NOV\n"
     ]
    }
   ],
   "source": [
    "flight=\"This is your itinerary trip to XXX! Here you have your boarding pass LA4214 AER-CDB 06NOV\"\n",
    "\n",
    "regex = r\"([A-Z]{2})(\\d{4})\\s([A-Z]{3})-([A-Z]{3})\\s(\\d{2}[A-Z]{3})\"\n",
    "\n",
    "# Find all matches of the flight information\n",
    "flight_matches = re.findall(regex, flight)\n",
    "    \n",
    "#Print the matches\n",
    "print(\"Airline: {} Flight number: {}\".format(flight_matches[0][0], flight_matches[0][1]))\n",
    "print(\"Departure: {} Destination: {}\".format(flight_matches[0][2], flight_matches[0][3]))\n",
    "print(\"Date: {}\".format(flight_matches[0][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive comments found [('like', 'movie', 'Avengers')]\n",
      "Positive comments found [('love', 'concert', 'Harry Potter')]\n",
      "Positive comments found [('enjoy', 'movie', 'Lie')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "sentiment_analysis=[\"I like the movie Avengers.\",\"And I love the concert Harry Potter.\" ,\"It enjoy amazing movie Lie.\"]\n",
    "\n",
    "regex_positive = r\"(love|like|enjoy).+?(movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for i in sentiment_analysis:\n",
    "    positive_matches = re.findall(regex_positive, i)\n",
    "    # Complete format to print out the results\n",
    "    print(\"Positive comments found {}\".format(positive_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like the movie Avengers.\n",
      "[('like', 'movie', 'Avengers')]\n",
      "And I love the concert Harry Potter.\n",
      "[('love', 'concert', 'Harry Potter')]\n",
      "It enjoy amazing movie Lie.\n",
      "[('enjoy', 'movie', 'Lie')]\n"
     ]
    }
   ],
   "source": [
    "for i in sentiment_analysis:\n",
    "    print(i)\n",
    "    positive=re.findall(regex_positive,i)\n",
    "    print(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments found [('dislike', 'Avengers')]\n",
      "Negative comments found [('hate', 'Harry Potter')]\n",
      "Negative comments found [('disapprove', 'Lie')]\n"
     ]
    }
   ],
   "source": [
    "# ?: Not Capturing\n",
    "sentiment_analysis=[\"I dislike the movie Avengers.\",\"And I hate the concert Harry Potter.\" ,\"It disapprove amazing movie Lie.\"]\n",
    "\n",
    "regex_negative = r\"(hate|dislike|disapprove).+?(?:movie|concert)\\s(.+?)\\.\"\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "\t# Find all matches of regex in tweet\n",
    "    negative_matches = re.findall(regex_negative, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print(\"Negative comments found {}\".format(negative_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backreference\n",
    ".search & .group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first contract is dated back to 2020. Particularly, the day 16 of the month 10.\n"
     ]
    }
   ],
   "source": [
    "contract=\" XXX was contracted with YYYY. Signed on 10/16/2020\"\n",
    "\n",
    "regex_dates = r\"Signed\\son\\s(\\d{2})/(\\d{2})/(\\d{4})\"\n",
    "dates = re.search(regex_dates, contract)\n",
    "\n",
    "# Assign to each key the corresponding match\n",
    "signature = {\n",
    "\t\"day\": dates.group(2),\n",
    "\t\"month\": dates.group(1),\n",
    "\t\"year\": dates.group(3)\n",
    "}\n",
    "# Complete the format method to print-out\n",
    "print(\n",
    "    \"Our first contract is dated back to {data[year]}. Particularly, the day {data[day]} of the month {data[month]}.\".format(data=signature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your tag body is closed\n",
      "Close your head tag!\n"
     ]
    }
   ],
   "source": [
    "html_tags=[\"<body> I don't know how to use html, but I will try to pretend I know how </body>\", \"<head>I hope this is How you do it\"]\n",
    "for string in html_tags:\n",
    "    # Complete the regex and find if it matches a closed HTML tags\n",
    "    match_tag =  re.match(r\"<(\\w+)>.*?<(/\\1)>\", string)\n",
    " \n",
    "    if match_tag:\n",
    "        # If it matches print the first group capture\n",
    "        print(\"Your tag {} is closed\".format(match_tag.group(1))) \n",
    "    else:\n",
    "        # If it doesn't match capture only the tag \n",
    "        notmatch_tag = re.match(r\"<(\\w+)>\", string)\n",
    "        # Print the first group capture\n",
    "        print(\"Close your {} tag!\".format(notmatch_tag.group(1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look ahead Vs Look behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learn', 'in']\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis=\"It is hard to learn python programming. But it is necessary to be fluence in Python to be a data analyst\"\n",
    "look_ahead = re.findall(r\"\\w+(?=\\s[pP]ython)\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['programming', 'to']\n"
     ]
    }
   ],
   "source": [
    "look_behind = re.findall(r\"(?<=\\s[pP]ython\\s)\\w+\", sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "print(look_behind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellphones=['654-8764-439434-01',\"654-8764-439434\",\"8764-439434-01\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['8764-439434-01']\n"
     ]
    }
   ],
   "source": [
    "for phone in cellphones:\n",
    "    # Get all phone numbers not have firt 3 digits\n",
    "    number = re.findall(r\"(?<!\\d{3}-)\\d{4}-\\d{6}-\\d{2}\", phone)\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['654-8764-439434']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for phone in cellphones:\n",
    "    # Get all phone numbers not have last two digits\n",
    "    number = re.findall(r\"\\d{3}-\\d{4}-\\d{6}(?!-\\d{2})\", phone)\n",
    "    print(number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
